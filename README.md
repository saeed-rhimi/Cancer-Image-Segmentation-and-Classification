
# Project Title

Cancerous Skin Lesion Segmentation and Classification

## Overview

This project aims to detect and classify cancerous skin lesions using state-of-the-art deep learning models. The main focus is on segmenting the lesions from skin images and classifying them into cancerous and non-cancerous categories. The project leverages pre-trained models like DeepLabV3 and Mask R-CNN for segmentation tasks and a custom ResNet classifier for classification tasks. Additionally, a U-Net model is used to improve segmentation accuracy.

## Table of Contents

1. [Installation](#installation)
2. [Dataset](#dataset)
3. [Preprocessing](#preprocessing)
4. [Models](#models)
   - [DeepLabV3](#deeplabv3)
   - [Mask R-CNN](#mask-r-cnn)
   - [ResNet Classifier](#resnet-classifier)
   - [U-Net](#u-net)
5. [Training](#training)
6. [Evaluation](#evaluation)
7. [Results](#results)
8. [Usage](#usage)
9. [Contributing](#contributing)
10. [License](#license)

## Installation

### Prerequisites

Before you begin, ensure you have met the following requirements:
- You have installed the latest version of Python.
- You have a basic understanding of Python and deep learning libraries such as PyTorch.
- You have access to a GPU for training the models (recommended but not required).

### Steps

1. **Clone the repository:**

    ```bash
    git clone https://github.com/saeed-rhimi/Cancer-Image-Segmentation-and-Classification.git
    cd Cancer-Image-Segmentation-and-Classification
    ```

3. **Install the required packages:**
    Ensure you have pip installed, then run:
   
    ```bash
    pip install -r requirements.txt
    ```

This will install all the necessary libraries such as PyTorch, torchvision, segmentation_models_pytorch, and other dependencies.

## Dataset

The dataset should include images of skin lesions and their corresponding labels in a CSV file. The dataset directory structure should be as follows:

```
dataset/
├── processed_images/
├── deeplabv3_masks/
├── maskrcnn_masks/
└── label_final_images.csv
```

- **`processed_images/`**: This folder contains the raw images of skin lesions.
- **`deeplabv3_masks/`**: This folder will store the masks generated by the DeepLabV3 model.
- **`maskrcnn_masks/`**: This folder will store the masks generated by the Mask R-CNN model.
- **`label_final_images.csv`**: This CSV file should have two columns: `image_name` and `target`. The `image_name` column should contain the names of the images, and the `target` column should contain binary labels (1 for cancerous, 0 for non-cancerous).

## Preprocessing

### Standardize Image Names

To ensure consistency, image names in the CSV file are standardized to have a `.jpg` extension. This step is crucial for correctly loading and processing the images later.

### Verify Image Channels

The project includes a verification step to check the number of channels in each image. Images with more than three channels are flagged, as the models expect images with three channels (RGB).

## Models

### DeepLabV3

DeepLabV3 is a semantic segmentation model pre-trained on the COCO dataset. It is used in this project to generate segmentation masks for images labeled as cancerous. The model is loaded with pre-trained weights to leverage the learned features and improve segmentation accuracy.

### Mask R-CNN

Mask R-CNN is another powerful segmentation model pre-trained on the COCO dataset. It not only detects objects in the images but also generates masks for these objects. In this project, Mask R-CNN is used to generate segmentation masks for cancerous skin lesions.

### ResNet Classifier

A custom ResNet-18 classifier is employed to classify images into cancerous and non-cancerous categories. The model is initialized with ImageNet weights and fine-tuned on the skin lesion dataset. The classifier helps in identifying which images should undergo segmentation.

### U-Net

U-Net is a widely used model for biomedical image segmentation. In this project, a U-Net model with a ResNet34 encoder pre-trained on ImageNet is used. This model is trained to generate precise segmentation masks for skin lesions.

## Training

### ResNet Classifier

The ResNet classifier is trained for a specified number of epochs. During training, the model's parameters are updated to minimize the cross-entropy loss between the predicted and true labels. The training and validation loss are tracked to monitor the model's performance and prevent overfitting.

### U-Net

The U-Net model is trained to minimize the binary cross-entropy loss between the predicted and true masks. The training process involves feeding images and their corresponding masks into the model, computing the loss, and updating the model's parameters using an optimizer. The training and validation loss are tracked to ensure the model learns effectively.

## Evaluation

### Loss Evaluation

The training and validation loss for both the ResNet classifier and U-Net model are evaluated after each epoch. This evaluation helps in understanding the model's learning progress and in making necessary adjustments to the training process.

### Mask Directory Check

After generating masks using DeepLabV3 and Mask R-CNN, the script checks if the mask directory exists and updates the DataFrame to indicate whether a mask exists for each image. This information is crucial for further processing and training steps.

## Results

### Visualizations

The project includes functions to visualize the original image, true mask, and predicted mask. This visualization helps in understanding the model's performance qualitatively. Random samples from the dataset are selected, and their predictions are displayed to provide insights into the model's accuracy.

## Usage

To use the trained models, follow these steps:

1. Ensure you have the required dataset structure and preprocessed data.
2. Load the trained model weights.
3. Use the provided functions to preprocess new images and generate predictions.

The project includes scripts to handle each of these steps, ensuring a smooth workflow from data preprocessing to model inference.

## Contributing

Contributions are welcome! If you have any suggestions or improvements, please submit a pull request or open an issue to discuss your ideas. Whether it's improving the documentation, adding new features, or fixing bugs, your contributions are greatly appreciated.

## License

This project is licensed under the MIT License. This means you can freely use, modify, and distribute the code, provided you include the original license and copyright notice. See the `LICENSE` file for more details.
